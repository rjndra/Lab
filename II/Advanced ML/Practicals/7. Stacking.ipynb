{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking\n",
        "\n",
        "Stacking is a way to combine the outcome of multiple ML models. Stacking is an ensemble which uses a meta-learning that learns the best combination for the prediction from multiple ML models. Other ensemble techniques, bagging and boosting, used homogeneous weak learners but stacking often makes use of heterogeneous weak learners.\n",
        "\n",
        "This techniques make use of meta learner which tunes based on the prediction from different heterogeneous dataset. A metal-learner takes input a prediction value from the various model and learns to approximate final prediction. The prediction value from machine learnings are the feature input for the meta-learner. This final layer of meta-learner is stacked on top of other machine learning models hence, the name **Stacking**."
      ],
      "metadata": {
        "id": "fxFzvU15GosR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITzOiMpU6oDD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import classifiers from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Import accuracy metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Import stacking ensemble\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Import training and test data splitter\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "breast_cancer_ds = load_breast_cancer()\n",
        "\n",
        "# Transform X dataframe\n",
        "X = pd.DataFrame(breast_cancer_ds['data'], columns = breast_cancer_ds['feature_names'])\n",
        "\n",
        "# Build a target dataframe\n",
        "y = pd.DataFrame(breast_cancer_ds['target'], columns = ['cancer_type'])\n",
        "\n",
        "# Check the shape of data\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZb7CYhiIjdk",
        "outputId": "d17a1c29-7292-44d8-c8c5-73ce55254bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((569, 30), (569, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Train test split of the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "\n",
        "# Create Decision Tree Classifier\n",
        "dtree_clf = DecisionTreeClassifier()\n",
        "\n",
        "# Create Logistic Regression Classifier\n",
        "logistic_clf = LogisticRegression()\n",
        "\n",
        "# Create Support Vector Classifier\n",
        "support_vector_clf = SVC()\n",
        "\n",
        "# Create Gaussian Naive Bayes Classifier\n",
        "gaussian_nb_clf = GaussianNB()\n",
        "\n",
        "# Create K Nearest Neighbors Classifier\n",
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "# Create level 2 classifier for Stack\n",
        "level1_clf = LogisticRegression()\n",
        "\n",
        "\n",
        "level0 = list()\n",
        "level0.append(('dtree', DecisionTreeClassifier()))\n",
        "level0.append(('lr', LogisticRegression()))\n",
        "level0.append(('knn', KNeighborsClassifier()))\n",
        "level0.append(('svc', SVC()))\n",
        "level0.append(('nb', GaussianNB()))\n",
        "\n",
        "# Create Stacking Classifier\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators = level0,\n",
        "    final_estimator = level1_clf,\n",
        "    cv = 10\n",
        ")"
      ],
      "metadata": {
        "id": "ZUsZkNtwIr45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the classifiers\n",
        "dtree_clf.fit(X_train, y_train)\n",
        "logistic_clf.fit(X_train, y_train)\n",
        "support_vector_clf.fit(X_train, y_train)\n",
        "gaussian_nb_clf.fit(X_train, y_train)\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test samples using classifiers\n",
        "y_pred_dtree = dtree_clf.predict(X_test)\n",
        "y_pred_logistic = logistic_clf.predict(X_test)\n",
        "y_pred_svc = support_vector_clf.predict(X_test)\n",
        "y_pred_nb = gaussian_nb_clf.predict(X_test)\n",
        "y_pred_knn = gaussian_nb_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy for each classifiers\n",
        "acc_dtree = accuracy_score(y_test, y_pred_dtree)\n",
        "acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
        "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
        "acc_knn = accuracy_score(y_test, y_pred_knn)"
      ],
      "metadata": {
        "id": "NGW15IcZJnsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the individual accuracy\n",
        "print(\"Accuracy for Decision Tree: \", acc_dtree)\n",
        "print(\"Accuracy for Logistic Regression: \", acc_logistic)\n",
        "print(\"Accuracy for Support Vector Machine: \", acc_svc)\n",
        "print(\"Accuracy for Naive Bayes: \", acc_nb)\n",
        "print(\"Accuracy for K-Nearest Neighbors: \", acc_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsrqcObxLLZ-",
        "outputId": "b6a37a1a-ca26-4e9d-d6a8-249b7b16c8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Decision Tree:  0.9181286549707602\n",
            "Accuracy for Logistic Regression:  0.9415204678362573\n",
            "Accuracy for Support Vector Machine:  0.9064327485380117\n",
            "Accuracy for Naive Bayes:  0.935672514619883\n",
            "Accuracy for K-Nearest Neighbors:  0.935672514619883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the stack\n",
        "stack_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the stack\n",
        "y_pred_stack = stack_clf.predict(X_test)\n",
        "\n",
        "# Compute the accuracy\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "\n",
        "# print the accuracy for stack\n",
        "print(\"Accuracy for stacking: \", acc_stack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcBzonlIMvct",
        "outputId": "2411eb43-6dc8-4520-eecf-23745adc564e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for stacking:  0.9590643274853801\n"
          ]
        }
      ]
    }
  ]
}