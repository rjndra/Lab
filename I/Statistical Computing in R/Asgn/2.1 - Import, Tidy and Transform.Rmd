---
title: "Assignment 2.1 - Import, Tidy and Transform"
output:
  pdf_document: default
  html_document: default
date: "2023-04-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part I: You must use rvest packages for this:


**1. Get this data in R, make it tidy and do the necessary transformations: <https://www.mohfw.gov.in/> (Table: COVID-19 Statewise Status (Click to expand))**

**Importing the necessary pacakges**
```{r}
library(rvest)
library(dplyr)
```


```{r}
#Getting Data from Json File from API
json_data <- jsonlite::fromJSON("https://www.mohfw.gov.in/data/datanew.json")
class(json_data)
head(json_data)

# convert the data into a tibble
covid_data <- as_tibble(json_data)


# separate the state_name column into two columns for state name and union territory name
library(tidyr)
covid_data <- covid_data %>% 
  separate(state_name, into = c("state", "union_territory"), sep = " and ")
head(covid_data)

#Transforming columns to the correct data type
covid_data$sno <- as.integer(covid_data$sno)
covid_data$active <- as.integer(covid_data$active)
covid_data$positive <- as.integer(covid_data$positive)
covid_data$cured <- as.integer(covid_data$cured)
covid_data$death <- as.integer(covid_data$death)
covid_data$new_active <- as.integer(covid_data$new_active)
covid_data$new_positive <- as.integer(covid_data$new_positive)
covid_data$new_cured <- as.integer(covid_data$new_cured)
covid_data$new_death <- as.integer(covid_data$new_death)
covid_data$death_reconsille <- as.integer(covid_data$death_reconsille)
covid_data$total <- as.integer(covid_data$total)
covid_data$actualdeath24hrs<- as.integer(covid_data$actualdeath24hrs)

# Remove unnecessary columns for further analysis
tidy_covid_data <- covid_data %>% 
  select(state, active, cured, death)

head(tidy_covid_data)
```


**2. Get this data in R, make it tidy and do the necessary transformation: <https://covid19.who.int/table>**
```{r}
json_data <- jsonlite::fromJSON("https://covid19.who.int/page-data/index/page-data.json")
class(json_data)
head(json_data)

#Multiple Json file, unstructured data
```


**3. Why the original version of the imbd dataset by Kaggle was taken down? <https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata>**
<p>The original version of the IMDB dataset by Kaggle was taken down due to a dispute between Kaggle and the dataset's original creator, as well as potential issues related to data licensing and copyright infringement. The dataset contained a significant amount of data that was scraped from the IMDB website, which may have violated IMDB's terms of use and copyright laws. Additionally, there may have been concerns about the accuracy and completeness of the data, as it was obtained through scraping rather than official sources. As a result, the dataset was removed from Kaggle to avoid potential legal issues and to respect the intellectual property rights of IMDB and other data sources.</p>


**4. Comment on this website's web scrapping policy: <https://help.imdb.com/article/imdb/general-information/can-i-use-imdb-data-in-my-software/G5JTRESSHJBBHTGX#>**
<p>The web scraping policy of IMDb allows limited non-commercial use of their data as long as certain conditions are met. These conditions include agreeing to their copyright/conditions of use statement, using only the datasets made available by IMDb, not using data mining or similar online data gathering tools on their website, and acknowledging the source of the data when used. The policy also prohibits altering, republishing, reselling, or repurposing the data to create any kind of online/offline database of movie information. However, IMDb does not allow commercial use of their content and directs individuals interested in licensing their content for commercial use to seek further information on their website. Overall, the policy seems to be clear and straightforward, with specific guidelines on how the data can and cannot be used.</p>


## Part II: You must use the tidyverse package for these steps:

```{r}
library(tidyverse)
```

**5. Download the title.ratings.tsv.gz and title.basics.tsv.gz files in your computer from <https://datasets.imdbws.com/>**

**6. Copy these files by creating a new folder "imdb" inside the "documents" folder of your computer and unzip them there**

**7. Set the working directory to the "imdb" folder**
```{r}
setwd("/Users/arpan/Desktop/MDS/01 MDS I-I/MDS 503 - Statistical Computing with R/Lab/imdb")
```

**8. Import the "title.ratings.tsv" file**
```{r}
setwd("/Users/arpan/Desktop/MDS/01 MDS I-I/MDS 503 - Statistical Computing with R/Lab/imdb")
df_ratings <- read_tsv("title.ratings.tsv")
```

**9. Check the structure and get summary of all the variables**
```{r}
str(df_ratings)
summary(df_ratings)
```
<p>**Interpretation:** The "df_ratings" data frame has 3 columns - "tconst", "averageRating", and "numVotes". "tconst" is a character variable containing the unique identifier for each title in the dataset. "averageRating" is a numeric variable representing the average rating of the title, and "numVotes" is a numeric variable representing the number of votes the title has received on IMDb. The dataset contains 1,300,716 observations (rows).</p>

**10. Is this dataset "tidy"? Why?**
```{r}
head(df_ratings)
```
<p>The dataset is tidy because each observation represents a single row, and each variable has its own column.</p>

**11. Get scatterplot of "averageRating" and "numVotes"**
```{r}
plot(df_ratings$averageRating,df_ratings$numVotes)
```
<p>**Interpretation:** The scatterplot shows a positive relationship between the number of votes and the average rating. Titles with a higher number of votes tend to have higher average ratings. However, there are also some titles with a low number of votes that have high average ratings.</p>

**12. Import the "title.basics.tsv" file**
```{r}
setwd("/Users/arpan/Desktop/MDS/01 MDS I-I/MDS 503 - Statistical Computing with R/Lab/imdb")
df_basics <- read_tsv("title.basics.tsv")
```

**13. Check the structure and get summary of all the variables**
```{r}
str(df_basics)
summary(df_basics)
```

<p>**Interpretation:** The "df_basics" data frame has 9 columns - "tconst", "titleType", "primaryTitle", "originalTitle", "isAdult", "startYear", "endYear", "runtimeMinutes", and "genres". "tconst" is a character variable containing the unique identifier for each title in the dataset. "titleType" is a categorical variable indicating the type of title (e.g., movie, tv series). "primaryTitle" and "originalTitle" are character variables containing the primary and original titles of the title, respectively. "isAdult" is a binary variable indicating whether the title is classified as "adult" or not. "startYear" and "endYear" are numeric variables indicating the year the title was released or the range of years if the title was a tv series. "runtimeMinutes" is a numeric variable indicating the duration of the title in minutes. "genres" is a character variable indicating the genre(s) of the title. The dataset contains 9,770,643 observations (rows).</p>

```{r}
head(df_basics)
```

**14. Is this dataset "tidy"? Why?**
<p>The "title.basics.tsv" dataset is not tidy because it contains multiple values in the "genres" column separated by commas. This violates the tidy data principles because each cell should only contain a single value.</P>

**15. Join the "df_basics" variables in "df_ratings" using "left_join" function**
```{r}
##df_ratings <- left_join(df_ratings, df_basics[, c("tconst", "startYear", "runtimeMinutes", "genres")], by = "tconst")
df_ratings<- left_join(df_ratings,df_basics)
head(df_ratings)
```

**16. Get a scatterplot of "runtimeMinutes" and "averageRating" variables in "df_ratings"**
```{r}
plot(df_ratings$runtimeMinutes,df_ratings$averageRating)
```

**17. Get the frequency table of "genres" variable using the plyr package**
```{r}
library(plyr)
count(df_ratings, "genres")
```

**18. Create a "by_genres" object using group_by function with df_ratings data and genres variable:**
```{r}
by_genres <- group_by(df_ratings, genres)
```

**19. Get mean of "runtimeMinutes" variable using summarise function by genres, removing NA in "runtimeMinutes"**
```{r}
str(by_genres)
#non-numric field so making it numeric
by_genres$runtimeMinutes <- as.numeric(by_genres$runtimeMinutes)

by_genres %>%
  summarise(mean_runtime = mean(runtimeMinutes, na.rm = TRUE))
```

**20. Get mean of "runtimeMinutes" variable using summarise by genres without creating "by_genres" object:**
```{r}
df_ratings$runtimeMinutes <- as.numeric(df_ratings$runtimeMinutes)

df_ratings %>%
  group_by(genres) %>%
  summarise(mean_runtime = mean(runtimeMinutes, na.rm = TRUE))
```

**21. What is difference between step 19 and step 20? Which one do you prefer? Why? Interpret the result of your choice.**

<p>In step 19, we use the summarise() function with the by_genres object to group the data by genre and calculate the mean runtime for each group. We also include the na.rm = TRUE argument to remove any NA values in the runtimeMinutes variable.
In step 20, we use the summarise() function directly on the df_ratings dataset to group the data by genre and calculate the mean runtime for each group. We do not need to create a separate by_genres object for this.
Both approaches give us the same result, which is the mean runtime for each genre. However, step 19 removes NA values in the runtimeMinutes variable, whereas step 20 does not. If there are many NA values in the runtimeMinutes variable, step 19 may be preferred because it ensures that these values do not affect the calculation of the mean.
In summary, both approaches are valid and give the same result, but the choice between them may depend on the specific characteristics of the dataset, such as the number of NA values in the variable being summarized.</p>


**22. Filter df_ratings data with runtimeMinutes less than 150 minutes**
```{r}
df_ratings_movie150m <- df_ratings %>%
  filter(runtimeMinutes < 150)
```

**23. Get scatterplot of runtimeMinutes and averageRating variable for df_ratings_movie150m**
```{r}
plot(df_ratings_movie150m$runtimeMinutes,df_ratings_movie150m$averageRating)
```

**24. Arrange df_ratings_movie150m data in descending order by averageRating**
```{r}
best_worst_movies <- df_ratings_movie150m %>%
  arrange(desc(averageRating))
```

**25. Show the top 6 and last 6 movies based on the arranged dataset above**
```{r}
# Top 6 movies
head(best_worst_movies, 6)

# Last 6 movies
tail(best_worst_movies, 6)
```

**26. Get the averageRating of adult movies (isAdult variable) using mutate function and interpret it carefully**
```{r}
df_ratings <- df_ratings %>%
  mutate(adult_rating = ifelse(isAdult == 1, averageRating, NA))

mean(df_ratings$adult_rating, na.rm = TRUE)
```

<p>This first adds a new column "adult_rating" to the "df_ratings" data, which assigns the value of averageRating to adult movies (isAdult == 1) and NA to non-adult movies (isAdult == 0). Then, it calculates the mean of adult_rating while removing any missing values. The result is the average rating of adult movies.
**Interpretation:** The result of the code mean(df_ratings$adult_rating, na.rm = TRUE) is 6.338142. This means that the average rating of movies intended for adult audiences (as determined by the "isAdult" variable) is 6.338142. This value falls between the range of 1 and 10, where 1 represents the lowest possible rating and 10 represents the highest possible rating. Therefore, we can interpret this as the average quality of adult movies, as rated by the users in the IMDb dataset.</p>

**27. Divide the "df_ratings_movies150m" into training and testing dataset with 80% and 20% split with slice function**
```{r}
library(dplyr)

set.seed(123)
train <- df_ratings_movie150m %>% slice_sample(n = round(nrow(.) * 0.8))
test <- df_ratings_movie150m %>% slice(-which(row.names(.) %in% row.names(train)))
```

**28. Get mean, standard deviation, median and interquartile range of averageRating, numVotes and runtimeMinutes variable of training and testing data and interpret them carefully**
```{r}
# Mean, standard deviation, median, and interquartile range of training data
train_summary <- sapply(train[, c("averageRating", "numVotes", "runtimeMinutes")], function(x) c(mean = mean(x, na.rm = TRUE), 
                                                                                                 sd = sd(x, na.rm = TRUE), 
                                                                                                 median = median(x, na.rm = TRUE),
                                                                                                 IQR = IQR(x, na.rm = TRUE)))
print(train_summary)
```

<p>**Interpretation:**
The summary shows the descriptive statistics of the three variables in the training data of the df_ratings_movie150m dataset.
* The mean averageRating is 6.94, indicating that the average rating of movies in the training set is around 7 out of 10.

* The mean numVotes is 6226, which suggests that the average number of votes for movies in the training set is around 6226.

* The mean runtimeMinutes is 238 minutes, indicating that the average runtime of movies in the training set is around 238 minutes or 3 hours and 58 minutes.

* The standard deviation for averageRating, numVotes and runtimeMinutes are 1.31, 66966.26 and 813.20, respectively. The high value of standard deviation for numVotes and runtimeMinutes indicates high variability in these variables among the movies in the training data.

* The median averageRating is 7.1, indicating that half of the movies in the training set have a rating of 7 or higher and half have a rating lower than 7.1.

* The median numVotes is 61, suggesting that half of the movies in the training set have a number of votes of 61 or less and the other half have more than 61 votes.

* The median runtimeMinutes is 180 minutes or 3 hours, indicating that half of the movies in the training set have a runtime of 3 hours or less and the other half have a longer runtime.

* The IQR (interquartile range) for averageRating, numVotes and runtimeMinutes are 1.7, 367.75, and 63.75, respectively. The IQR gives the range of the middle 50% of the data. For example, the IQR for averageRating is 1.7, indicating that the middle 50% of movies have a rating between 5.9 and 7.6.
</P>


```{r}
# Mean, standard deviation, median, and interquartile range of testing data
test_summary <- sapply(test[, c("averageRating", "numVotes", "runtimeMinutes")], function(x) c(mean = mean(x, na.rm = TRUE), 
                                                                                               sd = sd(x, na.rm = TRUE), 
                                                                                               median = median(x, na.rm = TRUE),
                                                                                               IQR = IQR(x, na.rm = TRUE)))
print(test_summary)
```

<p>**Interpretation:**
For the test dataset, the mean averageRating is 6.92, the mean numVotes is 4060.57, and the mean runtimeMinutes is 248.35. The standard deviation of averageRating is 1.41, the standard deviation of numVotes is 34185.53, and the standard deviation of runtimeMinutes is 1162.62.
The median of averageRating is 7.20, the median of numVotes is 43, and the median of runtimeMinutes is 180.
The interquartile range (IQR) for averageRating is 1.90, the IQR for numVotes is 315, and the IQR for runtimeMinutes is 67.
Overall, the statistics for the test dataset are similar to those of the training dataset. However, the standard deviation of numVotes and runtimeMinutes are higher for the test dataset, indicating greater variability in those variables in the test dataset compared to the training dataset.
</p>

**29. Get histogram of averageRating, numVotes and runtimeMinutes variables of training and testing data; compare them and interpret them carefully**
```{r}
# Histograms for the variables in the training dataset
par(mfrow=c(1,3))
hist(train$averageRating, main = "Training - Average Rating")
hist(train$numVotes, main = "Training - Number of Votes")
hist(train$runtimeMinutes, main = "Training - Runtime (minutes)")
```

```{r}
# Histograms for the variables in the testing dataset
par(mfrow=c(1,3))
hist(test$averageRating, main = "Testing - Average Rating")
hist(test$numVotes, main = "Testing - Number of Votes")
hist(test$runtimeMinutes, main = "Testing - Runtime (minutes)")
```

<p>**Interpretation:**
*Histograms of the averageRating variable for both the training and testing data look like a bell-shaped curve, it indicates that the data is normally distributed. This is a desirable property as many statistical models assume that the data is normally distributed. Similar shapes, peaks, and spreads in the histograms of the averageRating variable of the training and testing data suggest that the model is likely to perform well on the testing data.

*The numVotes variable histogram for the training and testing data have a single bar on the left side suggests that the majority of the movies have a small number of votes. The difference in the thickness of the bar between the training and testing data indicates that the distribution of the numVotes variable is different between the two datasets.

*The histograms of the runtimeMinutes variable for the training and testing data have similar shapes, peaks, and spreads, it indicates that the distribution of the runtimeMinutes variable is similar between the two datasets. The fact that both histograms look right skewed suggests that there are more movies with shorter runtimes and fewer movies with longer runtimes.
</p>

**30. Get boxplot of averageRating, numVotes and runtimeMinutes variables of training and testing data; compare them and interpret them carefully**
```{r}
# Boxplots for training data
par(mfrow = c(1,3))
boxplot(train$averageRating, main = "Training Data - averageRating", ylab = "averageRating")
boxplot(train$numVotes, main = "Training Data - numVotes", ylab = "numVotes")
boxplot(train$runtimeMinutes, main = "Training Data - runtimeMinutes", ylab = "runtimeMinutes")
```

```{r}
# Boxplots for testing data
par(mfrow = c(1,3))
boxplot(test$averageRating, main = "Testing Data - averageRating", ylab = "averageRating")
boxplot(test$numVotes, main = "Testing Data - numVotes", ylab = "numVotes")
boxplot(test$runtimeMinutes, main = "Testing Data - runtimeMinutes", ylab = "runtimeMinutes")
```

<p>**Interpretation:**

* Average Rating: The boxplots for both the training and testing datasets are similar in shape, with medians close to 7.0 and IQRs between 1.5 and 2.0. However, the testing dataset has a slightly wider range of values and more outliers than the training dataset.

* Number of Votes: The boxplots for both the training and testing datasets have very different scales, with the testing dataset having much higher values than the training dataset. However, the shape of the boxplots is similar, with medians close to 50 and IQRs between 100 and 400. Both datasets have a large number of outliers.

* Runtime Minutes: The boxplots for both the training and testing datasets are similar in shape, with medians around 180 and IQRs between 75 and 100. However, the testing dataset has more outliers and a wider range of values than the training dataset.

</p>
